{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6NktdFdWoYa4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoorYeg2oa4G",
        "outputId": "31ecd14e-5938-4aef-d028-90fb3f1f8eef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NMsKwz_tWyue"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_tokenize_text(text):\n",
        "    text = re.sub(r'[^a-z\\s]', '', text.lower())\n",
        "    tokens = [w for w in text.split() if w not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "def jaccard_similarity(list1, list2):\n",
        "    set1, set2 = set(list1), set(list2)\n",
        "    return len(set1 & set2) / len(set1 | set2) if (set1 | set2) else 0\n",
        "\n",
        "def ngram_jaccard(text1, text2, n=2):\n",
        "    ngrams1 = set(ngrams(clean_tokenize_text(text1), n))\n",
        "    ngrams2 = set(ngrams(clean_tokenize_text(text2), n))\n",
        "    return len(ngrams1 & ngrams2) / len(ngrams1 | ngrams2) if (ngrams1 | ngrams2) else 0\n",
        "\n",
        "def ngram_cosine(text1, text2, n=2):\n",
        "    def to_ngram_string(text, n):\n",
        "        toks = clean_tokenize_text(text)\n",
        "        return [\"_\".join(ng) for ng in ngrams(toks, n)]\n",
        "    docs = [\" \".join(to_ngram_string(text1, n)), \" \".join(to_ngram_string(text2, n))]\n",
        "    vec = TfidfVectorizer()\n",
        "    tfidf_matrix = vec.fit_transform(docs)\n",
        "    return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "\n",
        "def semantic_similarity(text1, text2, model):\n",
        "    emb1 = model.encode(text1, convert_to_tensor=True)\n",
        "    emb2 = model.encode(text2, convert_to_tensor=True)\n",
        "    return util.cos_sim(emb1, emb2).item()\n",
        "\n",
        "def sentence_level_check(text1, text2, model, threshold=0.75):\n",
        "    sents1 = sent_tokenize(text1)\n",
        "    sents2 = sent_tokenize(text2)\n",
        "    flagged = []\n",
        "\n",
        "    for i, s1 in enumerate(sents1):\n",
        "        for j, s2 in enumerate(sents2):\n",
        "            sim = semantic_similarity(s1, s2, model)\n",
        "            if sim > threshold:\n",
        "                flagged.append((s1, s2, sim))\n",
        "    return flagged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy928g64of6Z",
        "outputId": "ae3182e0-5a7c-47a6-b169-b3894be9c075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jaccard (unigram): 0.1402\n",
            "Cosine (TF-IDF): 0.3318\n",
            "Semantic Similarity: 0.8852\n",
            "Bigram Jaccard: 0.0157\n",
            "Bigram Cosine: 0.0159\n",
            "\n",
            "Final Plagiarism Score: 0.4889\n"
          ]
        }
      ],
      "source": [
        "with open(\"data\\text1.txt\", \"r\") as f:\n",
        "    text1 = f.read()\n",
        "with open(\"data\\text2.txt\", \"r\") as f:\n",
        "    text2 = f.read()\n",
        "\n",
        "tokens_1 = clean_tokenize_text(text1)\n",
        "tokens_2 = clean_tokenize_text(text2)\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "jaccard_score = jaccard_similarity(tokens_1, tokens_2)\n",
        "cosine_sim = cosine_similarity(\n",
        "    TfidfVectorizer().fit_transform([' '.join(tokens_1), ' '.join(tokens_2)])[0:1],\n",
        "    TfidfVectorizer().fit_transform([' '.join(tokens_1), ' '.join(tokens_2)])[1:2]\n",
        ")[0][0]\n",
        "sem_score = semantic_similarity(text1, text2, model)\n",
        "bigram_jaccard = ngram_jaccard(text1, text2, n=2)\n",
        "bigram_cosine = ngram_cosine(text1, text2, n=2)\n",
        "\n",
        "print(f\"Jaccard (unigram): {jaccard_score:.4f}\")\n",
        "print(f\"Cosine (TF-IDF): {cosine_sim:.4f}\")\n",
        "print(f\"Semantic Similarity: {sem_score:.4f}\")\n",
        "print(f\"Bigram Jaccard: {bigram_jaccard:.4f}\")\n",
        "print(f\"Bigram Cosine: {bigram_cosine:.4f}\")\n",
        "\n",
        "\n",
        "def plagiarism_score(jaccard, cosine, semantic, bigram_j, bigram_c):\n",
        "    return (0.45 * semantic +\n",
        "            0.20 * cosine +\n",
        "            0.15 * jaccard +\n",
        "            0.10 * bigram_j +\n",
        "            0.10 * bigram_c)\n",
        "\n",
        "score = plagiarism_score(jaccard_score, cosine_sim, sem_score, bigram_jaccard, bigram_cosine)\n",
        "print(f\"\\nFinal Plagiarism Score: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6qx3JJyojjW",
        "outputId": "c53b0b81-34c1-4f96-c6e5-2ceb58825a7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Paraphrased Plagiarism\n",
            "\n",
            "Sentence-level suspicious matches:\n",
            "\n",
            "Text1: Artificial Intelligence (AI) has become one of the most influential technologies of the 21st century, reshaping industries and redefining the way people work, learn, and communicate.\n",
            "Text2: Artificial Intelligence (AI) is emerging as a defining technology of our time, influencing industries and altering the ways humans interact, study, and perform tasks.\n",
            "Similarity: 0.87\n",
            "\n",
            "Text1: At its core, AI refers to the simulation of human intelligence in machines that are designed to think, reason, and act in ways similar to humans.\n",
            "Text2: Simply put, AI involves creating machines that can mimic human thought processes and behaviors.\n",
            "Similarity: 0.85\n",
            "\n",
            "Text1: The growth of AI has been largely driven by advancements in machine learning, where algorithms are trained on vast amounts of data and continuously improve their accuracy without explicit programming.\n",
            "Text2: The rise of AI has been fueled by machine learning techniques, where systems are trained using massive datasets and refine their performance through experience rather than direct programming instructions.\n",
            "Similarity: 0.81\n",
            "\n",
            "Text1: In healthcare, AI supports doctors by analyzing medical images, predicting disease outbreaks, and personalizing treatments.\n",
            "Text2: Healthcare has seen remarkable applications of AI, including interpreting diagnostic scans, forecasting disease trends, and offering customized treatment plans.\n",
            "Similarity: 0.80\n",
            "\n",
            "Text1: In finance, AI-driven models detect fraudulent transactions, automate trading, and offer customer support through intelligent chatbots.\n",
            "Text2: The financial sector relies on AI tools to identify fraud, manage investments, and enhance customer service with conversational agents.\n",
            "Similarity: 0.79\n",
            "\n",
            "Text1: Autonomous systems, such as self-driving cars and drones, further highlight AI’s potential to change daily life and economic structures.\n",
            "Text2: Autonomous technologies, such as robotic delivery vehicles and driverless cars, demonstrate how AI could transform everyday life and global economies.\n",
            "Similarity: 0.81\n",
            "\n",
            "Text1: Ethical concerns around bias, transparency, and accountability are significant.\n",
            "Text2: Ethical issues related to fairness, transparency, and accountability remain unresolved.\n",
            "Similarity: 0.75\n",
            "\n",
            "Text1: There are also social implications, such as job displacement due to automation.\n",
            "Text2: Furthermore, automation threatens to displace certain job categories, raising concerns about employment and inequality.\n",
            "Similarity: 0.78\n",
            "\n",
            "Text1: Governments and organizations worldwide are now developing policies and guidelines to ensure the safe and responsible use of AI.\n",
            "Text2: To address these challenges, governments, researchers, and companies are establishing frameworks to regulate and guide AI’s development responsibly.\n",
            "Similarity: 0.75\n",
            "\n",
            "Text1: AI, therefore, is not just a technological revolution but also a societal one, requiring collaboration between engineers, policymakers, and communities to maximize benefits while minimizing risks.\n",
            "Text2: Ultimately, AI is not only a scientific breakthrough but also a societal shift.\n",
            "Similarity: 0.78\n"
          ]
        }
      ],
      "source": [
        "if jaccard_score > 0.6 or bigram_jaccard > 0.5 or score > 0.75:\n",
        "    print(\"❌ Copy-Paste Plagiarism\")\n",
        "elif sem_score > 0.75 and 0.4 < score <= 0.75:\n",
        "    print(\"⚠️ Paraphrased Plagiarism\")\n",
        "elif score <= 0.4:\n",
        "    print(\"✅ Original\")\n",
        "else:\n",
        "    print(\"⚠️ Borderline Case – Needs Manual Review\")\n",
        "\n",
        "print(\"\\nSentence-level suspicious matches:\")\n",
        "flagged = sentence_level_check(text1, text2, model, threshold=0.75)\n",
        "if flagged:\n",
        "    for s1, s2, sim in flagged:\n",
        "        print(f\"\\nText1: {s1}\\nText2: {s2}\\nSimilarity: {sim:.2f}\")\n",
        "else:\n",
        "    print(\"No highly similar sentences found.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
